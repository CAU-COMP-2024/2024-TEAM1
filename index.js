// server.js
const express = require('express');
const multer = require('multer');
const Tesseract = require('tesseract.js');
const { Configuration, OpenAIApi } = require('openai');
const path = require('path');
const fs = require('fs');

const app = express();
const port = 3000;

// public í´ë” ë‚´ ì •ì  íŒŒì¼ ì„œë¹™
app.use(express.static(path.join(__dirname, 'public')));

// ì´ë¯¸ì§€ ì—…ë¡œë“œë¥¼ ìœ„í•œ multer ì„¤ì •
// ì—…ë¡œë“œëœ íŒŒì¼ì€ ì„œë²„ ë©”ëª¨ë¦¬ì— ì €ìž¥ (memoryStorage)
const upload = multer({ storage: multer.memoryStorage() });

// OpenAI ì„¤ì •

// Configuration ê°ì²´ ìƒì„±
const configuration = new Configuration({
    apiKey: process.env.OPENAI_API_KEY, // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
  });
  
// OpenAIApi ê°ì²´ ìƒì„±
const openai = new OpenAIApi(configuration);

// OCR + GPT ì²˜ë¦¬ í•¨ìˆ˜
async function processImageAndGenerateText(fileBuffer) {
  try {
    // 1) OCR ì²˜ë¦¬ (í•œê¸€+ì˜ì–´ ë™ì‹œ ì¸ì‹)
    //    kor.traineddata, eng.traineddata ëª¨ë‘ tessdata í´ë”ì— ìžˆì–´ì•¼ í•¨
    const ocrResult = await Tesseract.recognize(
      fileBuffer, 
      'kor+eng',
      {
        // tessdata í´ë” ê²½ë¡œ ì„¤ì •
        // (__dirnameì€ í˜„ìž¬ server.js íŒŒì¼ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬)
        langPath: path.join(__dirname, 'tessdata'),
      }
    );

    const extractedText = ocrResult.data.text.trim();
    console.log('OCR ì¶”ì¶œ í…ìŠ¤íŠ¸:', extractedText);

    // 2) GPT APIë¥¼ í†µí•´ ë©”ì‹œì§€ ìƒì„±
    const prompt = `ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ìƒëŒ€ë°©ì—ê²Œ ë³´ë‚¼ ì§§ê³  ë§¤ë ¥ì ì¸ ë©”ì‹œì§€ë¥¼ 1~2ì¤„ ì •ë„ë¡œ ë§Œë“¤ì–´ì¤˜:\n\n${extractedText}\n\n`;

    const completion = await openai.createChatCompletion({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: `ë„ˆëŠ” ìƒí™©ì— ë§žì¶° ìƒëŒ€ë°©ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìž¬ë¯¸ìžˆê³  ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
          ë„ˆëŠ” í”ŒëŸ¬íŒ… ì•±ì„ ìœ„í•œ ëŒ€í™” ë³´ì¡° ì¸ê³µì§€ëŠ¥ì´ì•¼.
          ì‚¬ìš©ìž(í™”ìž)ëŠ” ì¸ì„ íƒ€ëŠ” ìƒëŒ€ ë˜ëŠ” ì¢‹ì•„í•˜ëŠ” ìƒëŒ€ì™€ ëŒ€í™”ë¥¼ í•˜ê³  ìžˆìœ¼ë©°,
          ë„ˆëŠ” ë‹¤ìŒì˜ ê·œì¹™ì„ ë”°ë¼ì•¼ í•´:
      
          1. í•­ìƒ ìƒëŒ€ê°€ í˜¸ê°ì„ ëŠë‚„ ë§Œí•œ, ê¸ì •ì ì´ê³  ë¶€ë“œëŸ¬ìš´ ì–´íˆ¬ë¡œ ë‹µë³€í•  ê²ƒ.
          2. ê°€ëŠ¥í•˜ë‹¤ë©´ ê°„ë‹¨í•œ ì´ëª¨í‹°ì½˜(ì˜ˆ: 'ðŸ˜Š', 'ðŸ˜†')ì´ë‚˜ ì•½ê°„ì˜ ìžì—°ìŠ¤ëŸ¬ìš´ ê°íƒ„ì‚¬(ì˜ˆ: 'ì•„í•˜', 'ì•„ ê·¸ëž˜??') ë“±ì„ ì‚¬ìš©í•´ì„œ ë‹µë³€ì— ìƒë™ê°ì„ ì¤„ ê²ƒ.
          3. ë‹µë³€ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, 1~3ë¬¸ìž¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ìž‘ì„±í•  ê²ƒ.
          4. ìƒëŒ€ë°©ì´ ì–´ë–¤ ì„±ê²©ì¸ì§€ë‚˜, ëŒ€í™” ìƒí™©ì´ ì–´ë–¤ì§€ì— ë”°ë¼ í†¤ì„ ì¡°ê¸ˆì”© ë§žì¶¤í™”í•  ê²ƒ.
          5. ë°˜ë§ í˜¹ì€ ì¡´ëŒ“ë§ ì—¬ë¶€ëŠ” ì‚¬ìš©ìžì˜ í”„ë¡¬í”„íŠ¸ì— ë§žì¶°, ìžì—°ìŠ¤ëŸ½ê²Œ ìœ ì§€í•  ê²ƒ.
          `,
        },
        {
          role: 'user',
          content: prompt,
        },
      ],
      max_tokens: 100,
      temperature: 0.7,
    });

    const generatedText = completion.data.choices[0].message.content.trim();
    return generatedText;
  } catch (error) {
    console.error(error);
    throw new Error('í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ');
  }
}

// ì´ë¯¸ì§€ ì—…ë¡œë“œ & ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
app.post('/upload', upload.single('screenshot'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.' });
    }

    // OCR & GPT ì²˜ë¦¬
    const resultText = await processImageAndGenerateText(req.file.buffer);
    
    // í´ë¼ì´ì–¸íŠ¸ë¡œ ê²°ê³¼ ì „ì†¡
    return res.json({ message: resultText });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: 'ì„œë²„ ì˜¤ë¥˜' });
  }
});

// í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì§ì ‘ ìž…ë ¥ ì˜ˆì‹œ (OCR ìƒëžµ, GPTë§Œ í…ŒìŠ¤íŠ¸í•  ë•Œ)
app.use(express.json()); // JSON íŒŒì‹±
app.post('/prompt', async (req, res) => {
  const { userInput } = req.body;
  if (!userInput) {
    return res.status(400).json({ error: 'í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.' });
  }

  try {
    // GPT API í˜¸ì¶œ
    const prompt = `ëŒ€í™” ìƒí™©:\n${userInput}\n\nìƒëŒ€ë°©ì—ê²Œ ë³´ë‚¼ ë§¤ë ¥ì ì¸ í•œ ë§ˆë””ë¥¼ ë§Œë“¤ì–´ì¤˜:`;
    const completion = await openai.createChatCompletion({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: `ë„ˆëŠ” ìƒí™©ì— ë§žì¶° ìƒëŒ€ë°©ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìž¬ë¯¸ìžˆê³  ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
          ë„ˆëŠ” í”ŒëŸ¬íŒ… ì•±ì„ ìœ„í•œ ëŒ€í™” ë³´ì¡° ì¸ê³µì§€ëŠ¥ì´ì•¼.
          ì‚¬ìš©ìž(í™”ìž)ëŠ” ì¸ì„ íƒ€ëŠ” ìƒëŒ€ ë˜ëŠ” ì¢‹ì•„í•˜ëŠ” ìƒëŒ€ì™€ ëŒ€í™”ë¥¼ í•˜ê³  ìžˆìœ¼ë©°,
          ë„ˆëŠ” ë‹¤ìŒì˜ ê·œì¹™ì„ ë”°ë¼ì•¼ í•´:
      
          1. í•­ìƒ ìƒëŒ€ê°€ í˜¸ê°ì„ ëŠë‚„ ë§Œí•œ, ê¸ì •ì ì´ê³  ë¶€ë“œëŸ¬ìš´ ì–´íˆ¬ë¡œ ë‹µë³€í•  ê²ƒ.
          2. ê°€ëŠ¥í•˜ë‹¤ë©´ ê°„ë‹¨í•œ ì´ëª¨í‹°ì½˜(ì˜ˆ: 'ðŸ˜Š', 'ðŸ˜†')ì´ë‚˜ ì•½ê°„ì˜ ìžì—°ìŠ¤ëŸ¬ìš´ ê°íƒ„ì‚¬(ì˜ˆ: 'ì•„í•˜', 'ì•„ ê·¸ëž˜??') ë“±ì„ ì‚¬ìš©í•´ì„œ ë‹µë³€ì— ìƒë™ê°ì„ ì¤„ ê²ƒ.
          3. ë‹µë³€ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, 1~3ë¬¸ìž¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ìž‘ì„±í•  ê²ƒ.
          4. ìƒëŒ€ë°©ì´ ì–´ë–¤ ì„±ê²©ì¸ì§€ë‚˜, ëŒ€í™” ìƒí™©ì´ ì–´ë–¤ì§€ì— ë”°ë¼ í†¤ì„ ì¡°ê¸ˆì”© ë§žì¶¤í™”í•  ê²ƒ.
          5. ë°˜ë§ í˜¹ì€ ì¡´ëŒ“ë§ ì—¬ë¶€ëŠ” ì‚¬ìš©ìžì˜ í”„ë¡¬í”„íŠ¸ì— ë§žì¶°, ìžì—°ìŠ¤ëŸ½ê²Œ ìœ ì§€í•  ê²ƒ.
          `,
        },
        {
          role: 'user',
          content: prompt,
        },
      ],
      max_tokens: 100,
      temperature: 0.7,
    });

    const responseText = completion.data.choices[0].message.content.trim();
    return res.json({ message: responseText });
  } catch (error) {
    console.error(error);
    return res.status(500).json({ error: 'ì˜¤ë¥˜ ë°œìƒ' });
  }
});

app.listen(port, () => {
  console.log(`Server running at http://localhost:${port}`);
});
